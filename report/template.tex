%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 4.0 (March 21, 2022)
%
% This template originates from:
% https://www.LaTeXTemplates.com
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	a4paper, % Paper size, specify a4paper (A4) or letterpaper (US letter)
	10pt, % Default font size, specify 10pt, 11pt or 12pt
]{CSUniSchoolLabReport}

\addbibresource{sample.bib} % Bibliography file (located in the same folder as the template)

%----------------------------------------------------------------------------------------
%	REPORT INFORMATION
%----------------------------------------------------------------------------------------

\title{Report 4: Partial Differential Equations (PDEs)} % Report title
\subtitle{Git: https://github.com/simonblaue/MCP-Ex4.git}

\author{Simon \textsc{Blaue}} % Author name(s), add additional authors like: '\& James \textsc{Smith}'


\date{\today} % Date of the report

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert the title, author and date using the information specified above

\vspace*{40px}

\begin{tabular}{l r}
	Universität Göttingen \\ % Date the experiment was performed
	Faculty of Physics \\
	Instructor: Prof. Dr. S. Schumann \\
	Tutors: Dr. E. Bothmann, M. Knobbe \\ % Partner names
\end{tabular}


% If you need to include an abstract, uncomment the lines below
%\begin{abstract}
%	Abstract text
%\end{abstract}

\newpage
%----------------------------------------------------------------------------------------
%	CONTENT
%----------------------------------------------------------------------------------------
% \headtopline
% \headsepline

\ohead{\pagemark}
\automark{subsection}

\section{Laplace Equation}

\subsection{Iterator methods}

First, lets check which method converges the fastest:

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{../saves_t1/number_of_convergence_steps.pdf}
	\caption{Number of steps until convergence concerning the Laplace error $\max\epsilon<1\times 10^{-3}$.}
\end{figure}

I observe that Gauß-Seidel and SOR with $\alpha=1.0$ need the same number of time steps as expected. The fastest method is SOR with  $\alpha=1.75$, because with $\alpha=1.99$ we get too close to unstable regimes. Obviously, SOR with $\alpha=0.5$ takes the longest, as the updating step is damped with the factor $\alpha$. Now, I am going to observe the evolution of the maximal error and the average error of the different methods.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
			\centering
			\includegraphics[width=\textwidth]{../saves_t1/av_errors_comp.pdf}
			\label{fig:av_errors}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
			\centering
			\includegraphics[width=\textwidth]{../saves_t1/max_errors_comp.pdf}
			\label{fig:max_errors}
	\end{subfigure}
	\caption{Maximal and average error for different iteration methods.}
	\label{fig:errors}
\end{figure}

As discussed before, SOR with $\alpha=1.0$ and Gauß-Seidel method are the same, hence I plotted only the latter. The error development for all methods besides SOR with$\alpha\geq 1.5$ seem qualitatively the same. However for higher $\alpha$ I observe indents in the curve, which seems to boost the algorithm. This is due to the algorithm taking bigger steps in the right direction once it found this direction. 
For $\alpha=1.99$ the curve is very rigid, and I was not sure, if it is really converged to the right solution, hence I plotted the result below. As it turns out the method also converges to the expected result.

\begin{figure}[H]
	\includegraphics[width=\textwidth]{../saves_t1/sor199_heatmap.pdf}
	\caption{Domain after iterating with the SOR 1.99 method to verify right convergence.}
\end{figure}

\subsection{SOR}

The natural question to ask is what happens for an even further boosted SOR method? I found that for $\alpha = 2.0$ the algorithm does not converge in  50000 steps. It seems that it would not have converged to the right domain, as the result shows stripes and the maximal error starts to fluctuate a lot after 100 time steps. The system can not recover from this.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{../saves_t1/broken_SOR_heatmap.pdf}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{../saves_t1/broken_SOR_error.pdf}
	% \caption{}
\end{figure}

\subsection{Infinite sum solution}

Now I will cross verify the iterative solution with an aproximated analytical solution. First have a look at the analytical "infinite" sum solution for different numbers of summands. 

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{../saves_t1/comp_lapplace_series_heatmap.pdf}
	\caption{Results for the "infinite" sum solution to the Laplace equation for different numbers of terms $n$.}
\end{figure}

As I increase the number of terms more and more sine functions are added left and right to the first one, and towards the top an exponential decay fills in. Comparing the "infinite" sum solution for 1000 terms with the Gauß-Seidel method reveals that the exponential decay is to weak, or the Gauß-Seidel method did not propagate long enough. Subtracting both results displays that at the edges the solutions are identical (yellow) in the top they do not fit together as the iterative solution did not propergate that far.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{../saves_t1/comp_laplace_heatmap.pdf}
		\caption{Comparison of the infinite sum solution with 1000 terms and the Gauß Seidel iterator solution.}
	\end{subfigure}
	\hfill
	\centering
	\begin{subfigure}[b]{0.6\textwidth}
		\includegraphics[width=\textwidth]{../saves_t1/difference_laplace_heatmap.pdf}
		\caption{Difference between the infinite sum solution with 1000 terms and the Gauß Seidel iterator solution.}
	\end{subfigure}
\end{figure}


\section{Diffusion}

In this task I implemented four different method for solving the diffusion equation. To verify they all converged to the same solution I plotted a time evolution of all of them. The time domain is in the y-axis, the rod domain in the x-axis, displayed in \autoref{fig:comp_diff_integ}. As expected, th rod cools down, but holds the qualitative temperature profile.

\subsection{Integration methods}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/rod_FTCS.pdf}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/rod_euler_back.pdf}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/rod_crank_nic.pdf}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/rod_dufort_frankel.pdf}
	\end{subfigure}
	\hfill
	\caption{Temporal evolution of the rod's temperature along the y-axis. The evolution seems to be the same for all four integration methods.}
	\label{fig:comp_diff_integ}
\end{figure}

\subsection{Error comparison}

To investigate the stability of the different method, I plotted the error against the analytical solution for different time step widths. I expect unconditionally stability for the implicit methods Euler Backwards, Crank-Nicolson and the Dufort-Frankel method. The FCTS method is not unconditionally stable and should result in a huge error at some large enough $\Delta t$, depending on $\Delta x$ ($\Delta x = 0.01$). However also the other methods have a time step dependent truncation error. I displayed their evolution individually in \autoref{fig:all_trunc_errors}.
For comparing the other erros I will cut off the instability of the FCTS scheme at an error of $\epsilon = 0.007$. I observe that the other schemes seem stable in the tested regime. In \cite{GBV-1778472117} the error development for Crank-Nicolson is given by order of $\Delta t^2$ for Euler Backwards it is given by $\Delta t$. Unfortunately this is not what I have found with my simulation, perhaps the space resolution is to coarse.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{../saves_t2/error_comp_diffusion.pdf}
	\caption{Error comparison for the different methods}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/error_development_fcts.pdf}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/error_development_eb.pdf}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/error_development_cn.pdf}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{../saves_t2/error_development_df.pdf}
	\end{subfigure}
	\hfill
	\caption{Errors in their full domain to check, wether they are stable or diverge at some point. This can be observed for the FCTS scheme.}
	\label{fig:all_trunc_errors}
\end{figure}


\section{Solitons}

\subsection{Numerical method}

We write $u(x,t)\rightarrow u_{j}^n (j\Delta x, n\Delta t) = U_j^n$. For the time derivative we have 
\begin{align}
	\pdv{u}{t} = \frac{u_{j-1}^n-u_{j+1}^n}{2\Delta t} + \mathscr{O}(\Delta t^2).
\end{align}
For the first space derivative we have
\begin{align}
	\pdv{u}{x} = \frac{u_{j-1}^n-u_{j+1}^n}{2\Delta x}+ \mathscr{O}(\Delta x^2).
\end{align}

To get the third order space derivative I expand $u(x,t)$ around $(x\pm\Delta x, t)$ and $(x\pm 2\Delta x, t)$. With $\pdv{u}{x} = u_x$ this reads as follows

\begin{align*}
	u(x\pm\Delta x, t) &= u \pm u_{x} \Delta x + u_{xx} \frac{\Delta x^2}{2}\pm u_{xxx} \frac{\Delta x^3}{6} + u_{xxxx}\frac{\Delta x^4}{24} + \mathscr{O}(\Delta x^5) \\
	u(x\pm 2\Delta x, t) &= u \pm u_{x} 2\Delta x + u_{xx} 2 \Delta x^2\pm u_{xxx} \frac{4\Delta x^3}{3} + u_{xxxx}\frac{2\Delta x^4}{3} + \mathscr{O}(\Delta x^5)
\end{align*}

Rewrite $u(x\pm\Delta x, t) = u_{j\pm1}^n$ and $u(x\pm2\Delta x, t) = u_{j\pm2}^n$ and calculate

\begin{align*}
	&\quad u_{j+2}^n - 2u_{j+1}^n + 2u_{j-1}^n - u_{j-2}^n \\ 
	&=  u + u_{x} 2\Delta x + u_{xx} 2 \Delta x^2+ u_{xxx} \frac{4\Delta x^3}{3} + u_{xxxx}\frac{2\Delta x^4}{3} + \mathscr{O}(\Delta x^5) \\
	&\quad- 2u - 2u_{x} \Delta x - 2u_{xx} \frac{\Delta x^2}{2}- 2u_{xxx} \frac{\Delta x^3}{6} - 2u_{xxxx}\frac{\Delta x^4}{24} - 2\mathscr{O}(\Delta x^5) \\
	&\quad + 2u - 2u_{x} \Delta x + 2u_{xx} \frac{\Delta x^2}{2} - 2u_{xxx} \frac{\Delta x^3}{6} + 2u_{xxxx}\frac{\Delta x^4}{24} + 2\mathscr{O}(\Delta x^5) \\
	&\quad -u + u_{x} 2\Delta x - u_{xx} 2 \Delta x^2+ u_{xxx} \frac{4\Delta x^3}{3} - u_{xxxx}\frac{2\Delta x^4}{3} - \mathscr{O}(\Delta x^5)\\
	&= 2 u_{xxx} \frac{4}{3} \Delta x^3 - 4 u_{xxx} \frac{1}{6} \Delta x^3 \\
	&= u_{xxx} \left( \frac{8-2}{3} \Delta x^3  \right) \\
	&\Leftrightarrow \pdv{^3u}{x^3} = \frac{u_{j+2}^n - 2u_{j+1}^n + 2u_{j-1}^n - u_{j-2}^n}{2 \Delta x^3}
\end{align*}


The first term $u(x,t)$ is approximated by 
\begin{align*}
	u(x,t) = \frac{u_{j-1}^n + u_j^n + u_{j+1}^n}{3}
\end{align*}

Now we can put the four terms together to finally get

\begin{align*}
	\frac{u_{j}^{n-1}-u_{j}^{n+1}}{2\Delta t} + \epsilon \frac{u_{j-1}^n + u_j^n + u_{j+1}^n}{3} \frac{u_{j-1}^n-u_{j+1}^n}{2\Delta x} + \mu \frac{u_{j+2}^n - 2u_{j+1}^n + 2u_{j-1}^n - u_{j-2}^n}{2 \Delta x^3} = 0 \\
\end{align*}

\begin{align}
	u_j^{n+1} = u_j^{n-1} &- \frac{\epsilon}{3} \frac{\Delta t}{\Delta x} [u_{j-1}^n + u_j^n + u_{j+1}^n] [u_{j-1}^n-u_{j+1}^n] 
	\\ &- \mu \frac{\Delta t}{\Delta x^3} [u_{j+2}^n - 2u_{j+1}^n + 2u_{j-1}^n - u_{j-2}^n]\nonumber
\end{align}

\subsection{Stability condition}

The stability condition is given by

\begin{align*}
	\frac{\Delta t}{\Delta x} \left[\epsilon |u| + 4\frac{\mu}{\Delta x^2} \right] \leq 1
\end{align*}

This can be rewritten as 

\begin{align*}
	|u| \leq \frac{1}{\epsilon}\left[ \frac{\Delta x}{\Delta t} - 4\frac{\mu}{\Delta x^2} \right]
\end{align*}

With $\epsilon=0.2,\quad \mu=0.1,\quad \Delta x = 0.4,\quad \Delta t=0.1$ I get

\begin{align*}
	|u| \leq 7.5
\end{align*}
 
\subsection{Simulation of solitons}

I did an animation, which can be found in the git \href{https://github.com/simonblaue/MCP-Ex4.git}{repo} in the folder anim. When only plotting every 250th time step I get \autoref{fig:one_solition}. I observe that in this time range 4 solitary waves form. If I run the simulation longer, I get more and more waves. As the new waves are smaller at first, they should move slower as we now from the analytical solution (amplitude $\propto$ velocity). This is hard to observe in this representation, but could hold true. If we focus at time step 1001 and 2000 we can verify that the distance between the first amplitude and the second indeed grew. The stability condition $|u|\leq7.5$ holds true during the simulation time.

\begin{figure}
	\centering
	\includegraphics[width=0.85\textwidth]{../saves_t3/one_soliton.pdf}
	\caption{Time evolution beginning with one solitary wave, which splits in multiple.}
	\label{fig:one_solition}
\end{figure}

\subsubsection{Colliding solitons}

I again have a simulation of this in my git \href{https://github.com/simonblaue/MCP-Ex4.git}{repo}. Plotting every 1500th time step is shown in \autoref{fig:colliding_solitons}. I observe that after collision the smaller wave moves in the same direction as the bigger wave. The bigger waves moves in the same direction as before but slower. The stability condition $|u|\leq7.5$ holds true during the simulation time.

\begin{figure}
	\centering
	\includegraphics[width=0.85\textwidth]{../saves_t3/colliding_solitons.pdf}
	\caption{Time evolution of two colliding solitary waves.}
	\label{fig:colliding_solitons}
\end{figure}

%----------------------------------------------------------------------------------------
%	DISCUSSION
%----------------------------------------------------------------------------------------

% \section{Discussion}



%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------
\newpage

\printbibliography % Output the bibliography

%----------------------------------------------------------------------------------------

\end{document}